{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82ba5cb0-b81e-43ea-acfa-e661fff2572c",
      "metadata": {
        "id": "82ba5cb0-b81e-43ea-acfa-e661fff2572c"
      },
      "source": [
        "# **Machine Learning using scikit-learn**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a251b12-73f7-4007-8f91-a866b8539ded",
      "metadata": {
        "id": "3a251b12-73f7-4007-8f91-a866b8539ded"
      },
      "source": [
        "As a reminder, below are the following best practices we should follow when performing Machine Learning in Python:\n",
        "\n",
        "1. Perform all pre-processing steps within cross-validation\n",
        "2. Measure model performance (and model selection) using cross-validation\n",
        "3. Follow literate programming practices to make code readable and make collaboration easier\n",
        "\n",
        "## Problem Formulation\n",
        "\n",
        "In this example, we will use IBM's HR Attrition dataset, available here: https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset.\n",
        "The dataset contains data on 1470 employees. The variables covered in this dataset focus heavily on demographic attributes (e.g. gender, age and race), social related attributes (e.g. marital status) and work related attributes (e.g. tenure and pay)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5d51761d-af0e-411f-9375-54bcd91a62db",
      "metadata": {
        "id": "5d51761d-af0e-411f-9375-54bcd91a62db"
      },
      "outputs": [],
      "source": [
        "#tables and visualizations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#machine learning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, StandardScaler\n",
        "from sklearn import config_context\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87e69be8-1415-482e-adc2-4d71a697535b",
      "metadata": {
        "id": "87e69be8-1415-482e-adc2-4d71a697535b"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "Here we first load the data into python using pandas and read it in as a pandas dataframe which is the format which we will use throughout the example. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6b347d70-2e7b-4cdc-a290-ace614045711",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6b347d70-2e7b-4cdc-a290-ace614045711",
        "outputId": "ac9495f5-0cd9-4291-f71c-1e88e7422cdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 35 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   object\n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   int64 \n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EmployeeCount             1470 non-null   int64 \n",
            " 9   EmployeeNumber            1470 non-null   int64 \n",
            " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 11  Gender                    1470 non-null   object\n",
            " 12  HourlyRate                1470 non-null   int64 \n",
            " 13  JobInvolvement            1470 non-null   int64 \n",
            " 14  JobLevel                  1470 non-null   int64 \n",
            " 15  JobRole                   1470 non-null   object\n",
            " 16  JobSatisfaction           1470 non-null   int64 \n",
            " 17  MaritalStatus             1470 non-null   object\n",
            " 18  MonthlyIncome             1470 non-null   int64 \n",
            " 19  MonthlyRate               1470 non-null   int64 \n",
            " 20  NumCompaniesWorked        1470 non-null   int64 \n",
            " 21  Over18                    1470 non-null   object\n",
            " 22  OverTime                  1470 non-null   object\n",
            " 23  PercentSalaryHike         1470 non-null   int64 \n",
            " 24  PerformanceRating         1470 non-null   int64 \n",
            " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 26  StandardHours             1470 non-null   int64 \n",
            " 27  StockOptionLevel          1470 non-null   int64 \n",
            " 28  TotalWorkingYears         1470 non-null   int64 \n",
            " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 30  WorkLifeBalance           1470 non-null   int64 \n",
            " 31  YearsAtCompany            1470 non-null   int64 \n",
            " 32  YearsInCurrentRole        1470 non-null   int64 \n",
            " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 34  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(26), object(9)\n",
            "memory usage: 402.1+ KB\n"
          ]
        }
      ],
      "source": [
        "employee_df = pd.read_excel('IBM-HR-Data-Employee-Attrition.xlsx')\n",
        "employee_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "107620e0-89ee-4f53-ac2e-dd0d03b15b66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107620e0-89ee-4f53-ac2e-dd0d03b15b66",
        "outputId": "41ff7606-e935-400a-c031-427b463455ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age                         0\n",
              "Attrition                   0\n",
              "BusinessTravel              0\n",
              "DailyRate                   0\n",
              "Department                  0\n",
              "DistanceFromHome            0\n",
              "Education                   0\n",
              "EducationField              0\n",
              "EmployeeCount               0\n",
              "EmployeeNumber              0\n",
              "EnvironmentSatisfaction     0\n",
              "Gender                      0\n",
              "HourlyRate                  0\n",
              "JobInvolvement              0\n",
              "JobLevel                    0\n",
              "JobRole                     0\n",
              "JobSatisfaction             0\n",
              "MaritalStatus               0\n",
              "MonthlyIncome               0\n",
              "MonthlyRate                 0\n",
              "NumCompaniesWorked          0\n",
              "Over18                      0\n",
              "OverTime                    0\n",
              "PercentSalaryHike           0\n",
              "PerformanceRating           0\n",
              "RelationshipSatisfaction    0\n",
              "StandardHours               0\n",
              "StockOptionLevel            0\n",
              "TotalWorkingYears           0\n",
              "TrainingTimesLastYear       0\n",
              "WorkLifeBalance             0\n",
              "YearsAtCompany              0\n",
              "YearsInCurrentRole          0\n",
              "YearsSinceLastPromotion     0\n",
              "YearsWithCurrManager        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "employee_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3200837-3b0e-42f5-aac2-c2dc6dec3fd0",
      "metadata": {
        "id": "f3200837-3b0e-42f5-aac2-c2dc6dec3fd0"
      },
      "source": [
        "## Data cleaning and EDA\n",
        "\n",
        "We can now briefly explore our data. For now, we can observe that there are a zero NA values which will likely need imputation. We'll wait for this step so that we can put it within our training loop in case future data sets from IBM HR might have NA values. You are welcome to explore additional aspects of the data and build out 2-3 features on your own"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ae42a8db-457d-4532-934b-b4be3e6ce33b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae42a8db-457d-4532-934b-b4be3e6ce33b",
        "outputId": "d7c3dd6e-99d9-4682-9821-02d9ce8f7287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1470, 35)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "employee_df = employee_df.dropna(subset=['Attrition'])\n",
        "employee_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5898082",
      "metadata": {},
      "source": [
        "FEATURE ENGINEERING ONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e0ea3790",
      "metadata": {},
      "outputs": [],
      "source": [
        "unit_percentage = (employee_df['MonthlyIncome'].max() - employee_df['MonthlyIncome'].min()) / 10\n",
        "bins = [0, 1, 5, 10]\n",
        "bin_values = [i*unit_percentage for i in bins]\n",
        "employee_df['binned'] = pd.cut(employee_df['MonthlyIncome'], bin_values)\n",
        "employee_df['binned'] = employee_df['binned'].apply(lambda x: f\"{x.left:.0f}-{x.right:.0f}\")\n",
        "# By making it a string, the hot encoding in the pipeline wil automatically create a new column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08b0b84",
      "metadata": {},
      "source": [
        "FEATURE ENGINEERING TWO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7f1139a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       2\n",
            "1       3\n",
            "2       0\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "1465    3\n",
            "1466    0\n",
            "1467    4\n",
            "1468    3\n",
            "1469    1\n",
            "Name: tenure_to_promotion, Length: 1470, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "employee_df[\"tenure_to_promotion\"] = employee_df[\"YearsAtCompany\"] - employee_df[\"YearsInCurrentRole\"]\n",
        "print(employee_df[\"tenure_to_promotion\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "02c5bb25-8c26-47b0-b53c-f352babdb717",
      "metadata": {
        "id": "02c5bb25-8c26-47b0-b53c-f352babdb717"
      },
      "outputs": [],
      "source": [
        "class_column = 'Attrition'\n",
        "random_seed = 2435\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(employee_df.drop(columns=class_column), employee_df[class_column],\n",
        "                                                   test_size=0.25, random_state=random_seed, stratify=employee_df[class_column])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9774a06c-3c40-48c0-8834-2570785a918f",
      "metadata": {
        "id": "9774a06c-3c40-48c0-8834-2570785a918f"
      },
      "source": [
        "Quick sanity check to make sure that everything seems correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c32bbd1-5392-4281-a1a4-a38ed6dd6390",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "2c32bbd1-5392-4281-a1a4-a38ed6dd6390",
        "outputId": "224a7cce-ce84-4aa2-cb96-20a888ad2c37"
      },
      "outputs": [],
      "source": [
        "# X Train\n",
        "print('On X train: ')\n",
        "print('X train dimensions: ', X_train.shape)\n",
        "display(X_train.head())\n",
        "\n",
        "# X test\n",
        "print('\\nOn X test: ')\n",
        "print('X test dimensions: ', X_test.shape)\n",
        "display(X_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113d1ab3-739a-4e42-8500-92b6332b2475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "113d1ab3-739a-4e42-8500-92b6332b2475",
        "outputId": "732a2009-3463-4653-c28b-8b5d5fe74ccd"
      },
      "outputs": [],
      "source": [
        "# X Train\n",
        "print('On y train: ')\n",
        "print('y train dimensions: ', y_train.shape)\n",
        "display(y_train.head())\n",
        "\n",
        "# X test\n",
        "print('\\nOn y test: ')\n",
        "print('y test dimensions: ', y_test.shape)\n",
        "display(y_test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a76f5d1-05a4-4f81-8608-099b3b20abef",
      "metadata": {
        "id": "6a76f5d1-05a4-4f81-8608-099b3b20abef"
      },
      "source": [
        "## Establish the training pipeline\n",
        "\n",
        "We can now establish the training pipeline for our models. Since this is a process we would need to repeat several times, it's good to essentially functionalize the process so we do not need to re-write redundant code. Here, we can impute some values that were missing, and encode any categorical values. Note that these pipelines will change according to the model and methodology you choose - additionally, the pipelines will also change depending on the data types of the columns in your dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9ed44830-4039-4564-bde0-2b6661d672c5",
      "metadata": {
        "id": "9ed44830-4039-4564-bde0-2b6661d672c5"
      },
      "outputs": [],
      "source": [
        "# TODO: establish your own pipelines for the different data types\n",
        "cat_pipeline = Pipeline(steps=[('cat_impute', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
        "                               ('onehot_cat', OneHotEncoder(drop='if_binary'))])\n",
        "\n",
        "num_pipeline = Pipeline(steps=[('impute_num', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
        "                               ('scale_num', StandardScaler())])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "242c958a-894d-4259-9dfd-387ddf541144",
      "metadata": {
        "id": "242c958a-894d-4259-9dfd-387ddf541144"
      },
      "outputs": [],
      "source": [
        "# TODO: establish your preprocessing pipeline by your feature set\n",
        "\n",
        "preproc = ColumnTransformer([('cat_pipe', cat_pipeline, make_column_selector(dtype_include=object)),\n",
        "                             ('num_pipe', num_pipeline, make_column_selector(dtype_include=np.number))],\n",
        "                             remainder='passthrough')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "917a7dae-35ff-43b2-8186-dbe731d0f08d",
      "metadata": {
        "id": "917a7dae-35ff-43b2-8186-dbe731d0f08d"
      },
      "outputs": [],
      "source": [
        "# TODO: set up your modeling pipeline\n",
        "\n",
        "\n",
        "lr_pipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', LogisticRegression(penalty='elasticnet', solver='saga', tol=0.01))])\n",
        "\n",
        "rf_pipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', RandomForestClassifier())])\n",
        "\n",
        "gb_pipe = Pipeline(steps=[('preproc', preproc),\n",
        "                       ('mdl', GradientBoostingClassifier())])\n",
        "                       \n",
        "# Feel free to uncomment and edit the code below to visualize your overall pieline\n",
        "# with config_context(display='diagram'):\n",
        "#     display(your_pipeline_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32517c21-62d6-4d8c-81ad-aa08a3199ff3",
      "metadata": {
        "id": "32517c21-62d6-4d8c-81ad-aa08a3199ff3"
      },
      "source": [
        "## Cross-validation with hyperparameter tuning\n",
        "\n",
        "Now that we have our pipelines, we can now use this as part of cross validation and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f94e90d0-7785-48f4-a0cd-ff37090a92d9",
      "metadata": {
        "id": "f94e90d0-7785-48f4-a0cd-ff37090a92d9"
      },
      "outputs": [],
      "source": [
        "# TODO: set up your tuning grid \n",
        "lr_grid = {\n",
        "    'mdl__l1_ratio' : np.linspace(0,1,5),\n",
        "    'mdl__C': np.logspace(-1, 6, 3) \n",
        "}\n",
        "\n",
        "rf_grid = {\n",
        "    'mdl__n_estimators' : [10, 50, 100],\n",
        "    'mdl__max_depth' : [1, 5, 10],\n",
        "}\n",
        "\n",
        "gb_grid = {\n",
        "    'mdl__n_estimators' : [10, 50, 100],\n",
        "    'mdl__max_depth' : [1, 5, 10],\n",
        "}\n",
        "\n",
        "lr_search = GridSearchCV(lr_pipe, param_grid = lr_grid, cv = 5, return_train_score=True)\n",
        "rf_search = GridSearchCV(rf_pipe, param_grid = rf_grid, cv = 5, return_train_score=True)\n",
        "gb_search = GridSearchCV(gb_pipe, param_grid = gb_grid, cv = 5, return_train_score=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8f2cb02-c5eb-4fd4-9331-050191081014",
      "metadata": {
        "id": "e8f2cb02-c5eb-4fd4-9331-050191081014"
      },
      "outputs": [],
      "source": [
        "# TODO: fit your model\n",
        "\n",
        "lr_search.fit(X_train, y_train)\n",
        "rf_search.fit(X_train, y_train)\n",
        "gb_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "69f4874e-0de3-462f-95ef-d01ba648f7a4",
      "metadata": {
        "id": "69f4874e-0de3-462f-95ef-d01ba648f7a4"
      },
      "outputs": [],
      "source": [
        "# TODO: find the best performing model parameters and their values\n",
        "\n",
        "best_lr = lr_search.best_estimator_\n",
        "best_rf = rf_search.best_estimator_\n",
        "best_gb = gb_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289be208-bf90-4699-951e-b09a0289aa9d",
      "metadata": {
        "id": "289be208-bf90-4699-951e-b09a0289aa9d"
      },
      "source": [
        "## Final fit\n",
        "\n",
        "The final fit here is already present in the generated model due to the way we set our parameters in the grid search. If we want to look at the performance, we can do so. Here is a non-helpful description of the best model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a0c404f-514c-4f2c-98c9-506ca8ca1c46",
      "metadata": {
        "id": "9a0c404f-514c-4f2c-98c9-506ca8ca1c46"
      },
      "outputs": [],
      "source": [
        "# TODO: print your best estimator (pipeline)\n",
        "\n",
        "print(best_lr)\n",
        "print(best_rf)\n",
        "print(best_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3feb06cf-bf30-4383-9449-4153c0fa996e",
      "metadata": {
        "id": "3feb06cf-bf30-4383-9449-4153c0fa996e"
      },
      "source": [
        "## Variable importance\n",
        "\n",
        "Now we assess the importance in the selected model to reveal any potential insights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e4a10aec",
      "metadata": {},
      "outputs": [],
      "source": [
        "def variable_importance(model):\n",
        "\n",
        "    model.classes_\n",
        "\n",
        "    vip = model['mdl'].coef_[0]\n",
        "    vip\n",
        "\n",
        "    #get names in correct preproc order\n",
        "    cat_names = model.named_steps['preproc'].transformers_[0][1].named_steps['onehot_cat'].get_feature_names()\n",
        "    num_names = model.named_steps['preproc'].transformers_[1][2]\n",
        "\n",
        "    #create df with vip info\n",
        "    coef_info = pd.DataFrame({'feat_names':np.hstack([cat_names, num_names]), 'vip': vip})\n",
        "\n",
        "    #get sign and magnitude information\n",
        "    coef_info = coef_info.assign(coef_mag = abs(coef_info['vip']),\n",
        "                                 coef_sign = np.sign(coef_info['vip']))\n",
        "\n",
        "    #sort and plot\n",
        "    coef_info = coef_info.set_index('feat_names').sort_values(by='coef_mag', ascending=False)\n",
        "    plt.figure(figsize = (20,10))\n",
        "    sns.barplot(y=coef_info.index, x='coef_mag', hue='coef_sign', data=coef_info, orient='h', dodge=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1882727",
      "metadata": {},
      "outputs": [],
      "source": [
        "variable_importance(best_lr)\n",
        "#variable_importance(best_rf)\n",
        "#variable_importance(best_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa95eb91-77ec-4d33-a039-b2f9f95097fb",
      "metadata": {
        "id": "aa95eb91-77ec-4d33-a039-b2f9f95097fb"
      },
      "source": [
        "## Performance metrics on test data\n",
        "\n",
        "\n",
        "Here, we can see the performance of the model, which is pretty nice! We can also look into different scores specifically for more insight into the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "19f6f347-e01c-496a-ac3a-7e603361997f",
      "metadata": {
        "id": "19f6f347-e01c-496a-ac3a-7e603361997f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# TODO: print your classification report of your model\n",
        "\n",
        "def performance_metrics(model):\n",
        "\n",
        "    print(classification_report(y_test, model.predict(X_test)))\n",
        "\n",
        "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "    disp.plot()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594638a2-fe7e-4295-ac53-edca4db92565",
      "metadata": {
        "id": "594638a2-fe7e-4295-ac53-edca4db92565"
      },
      "outputs": [],
      "source": [
        "\n",
        "performance_metrics(best_lr)\n",
        "performance_metrics(best_rf)\n",
        "performance_metrics(best_gb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6a44e88d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_financial_value(model):\n",
        "\n",
        "    cm = confusion_matrix(y_test, model.predict(X_test))\n",
        "    tp = cm[0][0]\n",
        "    fp = cm[0][1]\n",
        "    fn = cm[1][0]\n",
        "    tn = cm[1][1]\n",
        "\n",
        "    # We are doing intervention on every person predicted to leave\n",
        "    total_predicted_leave = tn + fn\n",
        "    total_intervention_cost = total_predicted_leave * 2000\n",
        "\n",
        "    # Intervention works on 20% of those who were actually going to leave\n",
        "    decided_to_leave = int(tn * 0.8)\n",
        "\n",
        "    # $120k for each person that decided to leave and intervention didn't work on\n",
        "    replacement_cost = decided_to_leave * 120_000\n",
        "\n",
        "    total_cost = total_intervention_cost + replacement_cost\n",
        "    return total_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5340b45",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total cost of intervention LR model: ${calculate_financial_value(best_lr)}\")\n",
        "print(f\"Total cost of intervention RF model: ${calculate_financial_value(best_rf)}\")\n",
        "print(f\"Total cost of intervention GB model: ${calculate_financial_value(best_gb)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "employee-churn-template.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "88ad16ddd7eb93ca184db39662edbbf9caafda19639eb5c6a323cec5a0e46416"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('CS-5262')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
